% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize.R
\name{tokenize}
\alias{tokenize}
\title{Tokenize sentences using 'sudachi.rs'}
\usage{
tokenize(x, text_field = "text", docid_field = "doc_id", tagger)
}
\arguments{
\item{x}{A data.frame like object or a character vector to be tokenized.}

\item{text_field}{<\code{\link[rlang:args_data_masking]{data-masked}}>
String or symbol; column containing texts to be tokenized.}

\item{docid_field}{<\code{\link[rlang:args_data_masking]{data-masked}}>
String or symbol; column containing document IDs.}

\item{tagger}{A tagger function out of \code{\link[=create_tagger]{create_tagger()}}}
}
\value{
A tibble.
}
\description{
Tokenize sentences using 'sudachi.rs'
}
